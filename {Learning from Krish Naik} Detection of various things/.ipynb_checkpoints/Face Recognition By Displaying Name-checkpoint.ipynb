{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition By Displaying Name On Images :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_key(x,y,w,h):\n",
    "#     if [x,y,w,h] in values_list:\n",
    "#         key = keys_list[values_list.index([x,y,w,h])]\n",
    "#         return key\n",
    "#     for i in range(len(img_face)):\n",
    "#         for e in values_list[i]:\n",
    "#             if [x,y,w,h] == e:\n",
    "#                 key = keys_list[i]\n",
    "#                 return key\n",
    "#     else:\n",
    "#         key = \"Unknown Face\"\n",
    "#         return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eyes_classifier = cv2.CascadeClassifier(\"Haarcascades Files/haarcascade_eye.xml\")\n",
    "# face_classifier = cv2.CascadeClassifier(\"Haarcascades Files/haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# # # Images Collection for testing program :-\n",
    "# # img = cv2.imread(\"image_examples/obama.jpg\")\n",
    "# # img = cv2.imread(\"image_examples/img.jpg\")\n",
    "# # img = cv2.imread(\"image_examples/Trump.jpg\")\n",
    "# img = cv2.imread(\"image_examples/X.jpg\")\n",
    "# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# face = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "# if face is ():\n",
    "#     cv2.putText(img, \"No Face Found\", org=(30,30), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(0,0,255), thickness=2)\n",
    "#     cv2.imshow(\"No Face Detected\", img)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "# else:\n",
    "#     print(\"face variable having 4 values :-\\n x-coordinate = {},\\n y-coordinate = {},\\n width = {},\\n height = {}\".format(face[0,0], face[0,1], face[0,2], face[0,3]))\n",
    "\n",
    "\n",
    "# for i in face:\n",
    "#     x,y,w,h = i.ravel()\n",
    "#     print([x,y,w,h])\n",
    "\n",
    "# img_face = {\"Trump\":[53, 70, 215, 215], \"Shubham\":[[34, 33, 65, 65], [264, 105, 244, 244]], \"Obama\":[161, 66, 119, 119]}\n",
    "# keys_list = list(img_face.keys())\n",
    "# values_list = list(img_face.values())\n",
    "# print(keys_list)\n",
    "# print(values_list)\n",
    "\n",
    "# for (x,y,w,h) in face:\n",
    "#     cv2.rectangle(img, (x,y), (x+w, y+h), (150,250,2), 3)\n",
    "#     key = get_key(x,y,w,h)\n",
    "#     cv2.putText(img, key, org=(30,30), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(0,0,255), thickness=2)\n",
    "#     cv2.imshow(\"Face Detection\", img)\n",
    "#     cv2.waitKey(0)\n",
    "#     eyes_img = img[y:y+h, x:x+w]\n",
    "#     eyes_gray = gray[y:y+h, x:x+w]\n",
    "#     eyes = eyes_classifier.detectMultiScale(eyes_gray)\n",
    "#     for (ex, ey, ew, eh) in eyes:\n",
    "#         cv2.rectangle(eyes_img, (ex,ey), (ex+ew,ey+eh), (250,150,6), 2)\n",
    "#         cv2.imshow(\"Face & Eye Detection\", eyes_img)\n",
    "#         cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = {\"ssr\":98, \"mom\":[[67], [57]], \"dad\":64, \"didi\":93}\n",
    "# # Fetching a key from its value :-\n",
    "# \"\"\"1st way is :-\"\"\"\n",
    "# keys_list = list(x.keys())\n",
    "# values_list = list(x.values())\n",
    "# print(keys_list)\n",
    "# print(values_list)\n",
    "\n",
    "# # Now lets fetch the value :-\n",
    "# print(keys_list[values_list.index(64)])\n",
    "# # print(values_list[1].index(57))\n",
    "# for i in range(len(x)):\n",
    "#     for e in values_list[i]:\n",
    "#         if [57] == e:\n",
    "#             print(keys_list[1])\n",
    "\n",
    "# \"\"\"2nd way is (creating a function):-\"\"\"\n",
    "# # def get_key(val):\n",
    "# #     for (key,value) in x.items():\n",
    "# #         if value == val:\n",
    "# #             print(\"The Key of {} is {}.\".format(val, key))\n",
    "# # get_key(98)\n",
    "# # get_key(67)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition By Displaying Name on Webcam :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(x,y,w,h):\n",
    "    if [x,y,w,h] in values_list:\n",
    "        key = keys_list[values_list.index([x,y,w,h])]\n",
    "        return key\n",
    "    for i in range(len(img_face)):\n",
    "        for e in values_list[i]:\n",
    "            if [x,y,w,h] == e:\n",
    "                key = keys_list[i]\n",
    "                return key\n",
    "    else:\n",
    "        key = \"Unknown Face\"\n",
    "        return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "shubham_face = [[275, 205, 144, 144],\n",
    "[277, 208, 143, 143],\n",
    "[278, 206, 154, 154],\n",
    "[277, 208, 142, 142],\n",
    "[278, 208, 141, 141],\n",
    "[279, 209, 142, 142],\n",
    "[278, 209, 152, 152],\n",
    "[278, 209, 152, 152],\n",
    "[279, 209, 140, 140],\n",
    "[282, 213, 145, 145],\n",
    "[277, 209, 152, 152],\n",
    "[280, 214, 133, 133],\n",
    "[276, 208, 152, 152],\n",
    "[277, 211, 145, 145],\n",
    "[279, 212, 142, 142],\n",
    "[278, 214, 136, 136],\n",
    "[279, 215, 137, 137],\n",
    "[281, 217, 130, 130],\n",
    "[278, 215, 138, 138],\n",
    "[280, 219, 131, 131],\n",
    "[279, 215, 134, 134],\n",
    "[278, 213, 143, 143],\n",
    "[280, 213, 140, 140],\n",
    "[279, 215, 137, 137],\n",
    "[233, 192, 34, 34],\n",
    "[279, 213, 136, 136],\n",
    "[282, 216, 134, 134],\n",
    "[280, 214, 142, 142],\n",
    "[281, 217, 137, 137],\n",
    "[279, 214, 140, 140],\n",
    "[280, 215, 136, 136],\n",
    "[278, 213, 140, 140],\n",
    "[278, 211, 150, 150],\n",
    "[276, 210, 143, 143],\n",
    "[280, 213, 138, 138],\n",
    "[279, 214, 133, 133],\n",
    "[277, 211, 141, 141],\n",
    "[278, 214, 141, 141],\n",
    "[279, 216, 138, 138],\n",
    "[277, 211, 145, 145],\n",
    "[277, 212, 137, 137],\n",
    "[278, 213, 139, 139],\n",
    "[280, 218, 139, 139],\n",
    "[280, 216, 143, 143],\n",
    "[279, 212, 149, 149],\n",
    "[279, 214, 145, 145],\n",
    "[281, 212, 139, 139],\n",
    "[277, 211, 145, 145],\n",
    "[279, 214, 136, 136],\n",
    "[279, 217, 131, 131],\n",
    "[280, 212, 135, 135],\n",
    "[274, 206, 156, 156],\n",
    "[280, 210, 148, 148],\n",
    "[277, 211, 137, 137],\n",
    "[280, 211, 135, 135],\n",
    "[277, 208, 135, 135],\n",
    "[270, 205, 117, 117],\n",
    "[277, 206, 154, 154],\n",
    "[279, 210, 132, 132],\n",
    "[276, 207, 132, 132],\n",
    "[277, 209, 131, 131],\n",
    "[281, 211, 140, 140],\n",
    "[268, 202, 138, 138],\n",
    "[272, 203, 131, 131],\n",
    "[270, 204, 132, 132],\n",
    "[271, 201, 148, 148],\n",
    "[269, 201, 137, 137],\n",
    "[266, 202, 137, 137],\n",
    "[270, 201, 147, 147],\n",
    "[264, 198, 145, 145],\n",
    "[264, 200, 139, 139],\n",
    "[264, 201, 135, 135],\n",
    "[268, 201, 141, 141],\n",
    "[266, 200, 141, 141],\n",
    "[264, 198, 139, 139],\n",
    "[265, 197, 146, 146],\n",
    "[267, 196, 153, 153],\n",
    "[440, 221, 55, 55],\n",
    "[266, 197, 152, 152],\n",
    "[266, 199, 140, 140],\n",
    "[265, 194, 157, 157],\n",
    "[268, 196, 153, 153],\n",
    "[265, 196, 146, 146],\n",
    "[274, 201, 131, 131],\n",
    "[274, 200, 130, 130],\n",
    "[274, 196, 138, 138],\n",
    "[285, 197, 137, 137],\n",
    "[280, 194, 142, 142],\n",
    "[284, 187, 147, 147],\n",
    "[295, 192, 138, 138],\n",
    "[235, 193, 29, 29],\n",
    "[302, 192, 137, 137],\n",
    "[298, 188, 128, 128],\n",
    "[291, 187, 131, 131],\n",
    "[286, 186, 141, 141],\n",
    "[269, 188, 137, 137],\n",
    "[264, 188, 133, 133],\n",
    "[256, 190, 129, 129],\n",
    "[237, 189, 140, 140],\n",
    "[228, 190, 141, 141],\n",
    "[233, 189, 140, 140],\n",
    "[252, 188, 136, 136],\n",
    "[261, 186, 139, 139],\n",
    "[262, 185, 140, 140],\n",
    "[263, 187, 143, 143],\n",
    "[263, 186, 145, 145],\n",
    "[265, 188, 140, 140],\n",
    "[266, 188, 140, 140],\n",
    "[265, 189, 142, 142],\n",
    "[267, 191, 140, 140],\n",
    "[263, 201, 159, 159],\n",
    "[268, 221, 130, 130],\n",
    "[262, 218, 145, 145],\n",
    "[267, 226, 142, 142],\n",
    "[263, 226, 146, 146],\n",
    "[263, 226, 149, 149],\n",
    "[265, 227, 145, 145],\n",
    "[257, 219, 158, 158],\n",
    "[258, 219, 158, 158],\n",
    "[261, 221, 151, 151],\n",
    "[270, 226, 138, 138],\n",
    "[263, 221, 146, 146],\n",
    "[258, 214, 160, 160],\n",
    "[271, 218, 144, 144],\n",
    "[268, 214, 146, 146],\n",
    "[271, 214, 136, 136],\n",
    "[234, 192, 29, 29],\n",
    "[265, 188, 148, 148],\n",
    "[263, 188, 144, 144],\n",
    "[266, 184, 141, 141],\n",
    "[268, 183, 139, 139],\n",
    "[272, 183, 129, 129],\n",
    "[271, 182, 132, 132],\n",
    "[268, 180, 137, 137],\n",
    "[270, 180, 134, 134],\n",
    "[268, 182, 133, 133],\n",
    "[270, 181, 131, 131],\n",
    "[271, 181, 131, 131],\n",
    "[267, 180, 141, 141],\n",
    "[269, 182, 137, 137],\n",
    "[234, 190, 32, 32],\n",
    "[265, 181, 140, 140],\n",
    "[265, 185, 138, 138],\n",
    "[266, 184, 139, 139],\n",
    "[235, 192, 29, 29],\n",
    "[265, 185, 141, 141],\n",
    "[263, 187, 141, 141],\n",
    "[263, 190, 140, 140],\n",
    "[264, 191, 137, 137],\n",
    "[263, 191, 141, 141],\n",
    "[268, 193, 132, 132],\n",
    "[260, 192, 142, 142],\n",
    "[261, 191, 144, 144]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier(\"Haarcascades Files/haarcascade_frontalface_default.xml\")\n",
    "eyes_classifier = cv2.CascadeClassifier(\"Haarcascades Files/haarcascade_eye.xml\")\n",
    "\n",
    "img_face = {\"Shubham\":shubham_face}\n",
    "keys_list = list(img_face.keys())\n",
    "values_list = list(img_face.values())\n",
    "# print(keys_list)\n",
    "# print(values_list)\n",
    "\n",
    "# Doing some face & eyes detection with webcam :-\n",
    "video_capture = cv2.VideoCapture(0)  # Here, 0 means default webcam. If want to connect any secondary cam then put 1.\n",
    "while video_capture.isOpened():\n",
    "    _, frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    face = face_classifier.detectMultiScale(gray, 1.2, 5)\n",
    "    for (x,y,w,h) in face:\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (255, 0, 0), 4)\n",
    "        eyes_frame = frame[y:y+h, x:x+w]\n",
    "        eyes_gray = gray[y:y+h, x:x+w]\n",
    "        eyes = eyes_classifier.detectMultiScale(eyes_gray, 1.1, 3)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(eyes_frame, (ex,ey), (ex+ew, ey+eh), (109,5,2), 3)\n",
    "    key = get_key(x,y,w,h)\n",
    "    cv2.putText(frame, key, org=(30,30), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(0,0,255), thickness=3)\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "    if cv2.waitKey(1)==13:  # To exit simply press enter.\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
